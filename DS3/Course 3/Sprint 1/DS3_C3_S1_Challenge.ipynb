{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "piHvxBSUketk"
   },
   "source": [
    "# Task - 1 : Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DWMy-LDzSVN-"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from time import time\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52atuz3PktY3"
   },
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "AOt-JDujg3VX"
   },
   "outputs": [],
   "source": [
    "task1 = fetch_20newsgroups(subset='all',categories=['rec.motorcycles','sci.electronics'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2nrB3O-LqFFe"
   },
   "source": [
    "# Task 2: Vectorization and Building the Classifier Model\n",
    "\n",
    "1.Define a common function to meet the following criterion:\n",
    "- Convert the text data into vector form using the TF-IDF\n",
    "vectorization method.\n",
    "- Use the MultinomialNB() as classification method.\n",
    "- Find the confusion matrix and classification report.\n",
    "- Return the first 30 samples of predicted and actual output\n",
    "as two lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8N944G_5mWBI"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "def classify_text(text_data, labels):\n",
    "\n",
    "    docs_train, docs_test, y_train, y_test = train_test_split(text_data, labels, test_size = 0.2, random_state = 42)\n",
    "    \n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(docs_train)\n",
    "    \n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(X, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y_test, y_pred[:396])\n",
    "    cr = classification_report(y_test, y_pred[:396])\n",
    "    print(\"Confusion matrix:\\n\\n\", cm,'\\n')\n",
    "    print(\"Classification report:\\n\\n\", cr)\n",
    "    print('Actual :\\n',y_test[:30])\n",
    "    print('Predicted :\\n',y_pred[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-5qFQLI7nK9w",
    "outputId": "d2de4345-1cd6-4c47-8537-efd203673ec8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "\n",
      " [[ 87 114]\n",
      " [101  94]] \n",
      "\n",
      "Classification report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.43      0.45       201\n",
      "           1       0.45      0.48      0.47       195\n",
      "\n",
      "    accuracy                           0.46       396\n",
      "   macro avg       0.46      0.46      0.46       396\n",
      "weighted avg       0.46      0.46      0.46       396\n",
      "\n",
      "Actual :\n",
      " [1 1 1 1 0 0 1 0 0 0 1 1 0 0 1 1 1 0 1 0 1 1 0 1 0 1 0 0 0 1]\n",
      "Predicted :\n",
      " [0 1 1 0 0 1 1 1 1 1 0 1 0 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "classify_text(task1.data,task1.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eBnqKJhLkP5R"
   },
   "source": [
    "### 2. Invoke the method above by passing the classifier object, trian, and test datasets.\n",
    "### 3. Print the first 30 samples of predicted and actual output as a table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0_kXGuwE0Fnf",
    "outputId": "bf53c7da-b084-43dd-9948-02b5ed8d8011"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[395   3]\n",
      " [ 13 380]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       398\n",
      "           1       0.99      0.97      0.98       393\n",
      "\n",
      "    accuracy                           0.98       791\n",
      "   macro avg       0.98      0.98      0.98       791\n",
      "weighted avg       0.98      0.98      0.98       791\n",
      "\n",
      "\n",
      "Predicted output:\n",
      " [1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0]\n",
      "\n",
      "Actual output:\n",
      " [1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "def text_classification(classifier, train_data, test_data):\n",
    "    \n",
    "    TFIDF = TfidfVectorizer(stop_words='english')\n",
    "    X_train = TFIDF.fit_transform(train_data.data)\n",
    "    X_test = TFIDF.transform(test_data.data)\n",
    "\n",
    "    \n",
    "    clf = classifier.fit(X_train, train_data.target)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    \n",
    "    cm = confusion_matrix(test_data.target, y_pred)\n",
    "    cr = classification_report(test_data.target, y_pred)\n",
    "\n",
    "    \n",
    "    pred_output = list(y_pred[:30])\n",
    "    actual_output = list(test_data.target[:30])\n",
    "\n",
    "    return cm, cr, pred_output, actual_output\n",
    "\n",
    "task1 = fetch_20newsgroups(subset='all', categories=['rec.motorcycles', 'sci.electronics'])\n",
    "train = fetch_20newsgroups(subset='train', categories=['rec.motorcycles', 'sci.electronics'])\n",
    "test = fetch_20newsgroups(subset='test', categories=['rec.motorcycles', 'sci.electronics'])\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "\n",
    "cm, cr, pred_output, actual_output = text_classification(classifier, train, test)\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "print(\"\\nClassification report:\\n\", cr)\n",
    "print(\"\\nPredicted output:\\n\", pred_output)\n",
    "print(\"\\nActual output:\\n\", actual_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n6yk9xU416NZ"
   },
   "source": [
    "# Task - 3 : Classification on Additional Categories\n",
    "1. Add the following two categories to the previous input data:\n",
    "'rec.sport.baseball,\n",
    "'comp.graphics'\n",
    "2. Repeat all the steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "GUT97lSp12ne"
   },
   "outputs": [],
   "source": [
    "categories = ['rec.motorcycles', 'sci.electronics', 'rec.sport.baseball', 'comp.graphics']\n",
    "task2 = fetch_20newsgroups(subset='all', categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PH3pvSvC2VQ3"
   },
   "outputs": [],
   "source": [
    "def classify_text(text_data, labels):\n",
    "\n",
    "    docs_train, docs_test, y_train, y_test = train_test_split(text_data, labels, test_size = 0.2, random_state = 42)\n",
    "    \n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(docs_train)\n",
    "    \n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(X, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y_test, y_pred[:790])\n",
    "    cr = classification_report(y_test, y_pred[:790])\n",
    "    print(\"Confusion matrix:\\n\\n\", cm,'\\n')\n",
    "    print(\"Classification report:\\n\\n\", cr)\n",
    "    print('Actual :\\n',y_test[:30])\n",
    "    print('Predicted :\\n',y_pred[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Urj0Jl6N26OF",
    "outputId": "7aa3c0f7-8dd1-41bf-ab8b-aec11172a800"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "\n",
      " [[50 57 42 49]\n",
      " [44 61 45 53]\n",
      " [58 52 46 48]\n",
      " [56 41 44 44]] \n",
      "\n",
      "Classification report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.25      0.25       198\n",
      "           1       0.29      0.30      0.29       203\n",
      "           2       0.26      0.23      0.24       204\n",
      "           3       0.23      0.24      0.23       185\n",
      "\n",
      "    accuracy                           0.25       790\n",
      "   macro avg       0.25      0.25      0.25       790\n",
      "weighted avg       0.25      0.25      0.25       790\n",
      "\n",
      "Actual :\n",
      " [1 0 1 2 0 0 0 0 3 2 1 1 3 1 0 1 1 2 2 0 0 0 3 1 0 1 2 2 1 2]\n",
      "Predicted :\n",
      " [1 1 1 1 1 1 0 1 3 0 1 1 2 2 2 1 3 2 3 2 0 1 2 2 3 3 1 0 3 0]\n"
     ]
    }
   ],
   "source": [
    "classify_text(task2.data,task2.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_xr5Fd1a2-Bt",
    "outputId": "b0ec595b-3c3a-4560-bdea-7f3d00077a34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[354   3   9  23]\n",
      " [  0 395   1   2]\n",
      " [  0   3 394   0]\n",
      " [ 31  12   2 348]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91       389\n",
      "           1       0.96      0.99      0.97       398\n",
      "           2       0.97      0.99      0.98       397\n",
      "           3       0.93      0.89      0.91       393\n",
      "\n",
      "    accuracy                           0.95      1577\n",
      "   macro avg       0.94      0.95      0.94      1577\n",
      "weighted avg       0.94      0.95      0.94      1577\n",
      "\n",
      "\n",
      "Predicted output:\n",
      " [2, 2, 2, 1, 1, 3, 2, 2, 1, 1, 0, 2, 0, 1, 0, 0, 1, 2, 3, 0, 1, 1, 1, 0, 0, 2, 1, 0, 2, 3]\n",
      "\n",
      "Actual output:\n",
      " [2, 2, 2, 1, 1, 1, 2, 2, 1, 1, 0, 2, 0, 1, 0, 0, 1, 2, 3, 0, 1, 1, 1, 0, 0, 2, 1, 0, 2, 0]\n"
     ]
    }
   ],
   "source": [
    "def text_classification(classifier, train_data, test_data):\n",
    "    \n",
    "    TFIDF = TfidfVectorizer(stop_words='english')\n",
    "    X_train = TFIDF.fit_transform(train_data.data)\n",
    "    X_test = TFIDF.transform(test_data.data)\n",
    "\n",
    "    \n",
    "    clf = classifier.fit(X_train, train_data.target)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    \n",
    "    cm = confusion_matrix(test_data.target, y_pred)\n",
    "    cr = classification_report(test_data.target, y_pred)\n",
    "\n",
    "    \n",
    "    pred_output = list(y_pred[:30])\n",
    "    actual_output = list(test_data.target[:30])\n",
    "\n",
    "    return cm, cr, pred_output, actual_output\n",
    "\n",
    "task1 = fetch_20newsgroups(subset='all', categories=['rec.motorcycles', 'sci.electronics', 'rec.sport.baseball', 'comp.graphics'])\n",
    "train = fetch_20newsgroups(subset='train', categories=['rec.motorcycles', 'sci.electronics', 'rec.sport.baseball', 'comp.graphics'])\n",
    "test = fetch_20newsgroups(subset='test', categories=['rec.motorcycles', 'sci.electronics', 'rec.sport.baseball', 'comp.graphics'])\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "\n",
    "cm, cr, pred_output, actual_output = text_classification(classifier, train, test)\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "print(\"\\nClassification report:\\n\", cr)\n",
    "print(\"\\nPredicted output:\\n\", pred_output)\n",
    "print(\"\\nActual output:\\n\", actual_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59PJHJ496a9Z"
   },
   "source": [
    "# Task 4 : Predictions of Unseen Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "tZzZuvWm47HW"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(task2.data, task2.target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v71bGd3X5YE1",
    "outputId": "5904902f-4291-4ff3-a99d-51f04771edce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [WinError 10054]\n",
      "[nltk_data]     An existing connection was forcibly closed by the\n",
      "[nltk_data]     remote host>\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "CV = CountVectorizer(stop_words=stopwords.words('english'))\n",
    "X_train_vectors = CV.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "akKZrXZv59v0",
    "outputId": "236228b5-2a43-4a35-f05b-03132e116072"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_classifier = MultinomialNB()\n",
    "NB_classifier.fit(X_train_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "QqlSF1Rm5-iT"
   },
   "outputs": [],
   "source": [
    "test_data = [\n",
    "    \"What are the different parts of a computer?\",\n",
    "    \"Playing baseball is good for one's health.\",\n",
    "    \"In which games are you interested?\",\n",
    "    \"It is the unknown around the corner that turns my wheels.\",\n",
    "    \"I am interested in increasing the picture resolution of my computer.\",\n",
    "    \"The team might not win if there is rain.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "CNYpZ6z05-rD"
   },
   "outputs": [],
   "source": [
    "test_data_vectors = CV.transform(test_data)\n",
    "predicted_labels = NB_classifier.predict(test_data_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SVGLD8Xb6HK3",
    "outputId": "9c64e617-ef82-448e-e6c4-fd3cdb31b6d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the different parts of a computer? ==> sci.electronics\n",
      "Playing baseball is good for one's health. ==> rec.sport.baseball\n",
      "In which games are you interested? ==> rec.sport.baseball\n",
      "It is the unknown around the corner that turns my wheels. ==> rec.motorcycles\n",
      "I am interested in increasing the picture resolution of my computer. ==> comp.graphics\n",
      "The team might not win if there is rain. ==> rec.sport.baseball\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test_data)):\n",
    "    print(f\"{test_data[i]} ==> {task1.target_names[predicted_labels[i]]}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
