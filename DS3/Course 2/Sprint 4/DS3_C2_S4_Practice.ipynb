{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48daaf45",
   "metadata": {},
   "source": [
    "# Task 1 :\n",
    "\n",
    "- Represent text 3 in vector form using BOW. Provide the following for the words 'review' and 'scary' :\n",
    "- a) BOW vector representation\n",
    "- b) Dictionary values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1efe209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc781aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2a3c7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from typing import Dict,List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58dbed45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Sentence : \n",
      " This movie is very sacry and long.\n",
      "\n",
      " Bag of words representation : \n",
      " [(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1)]\n",
      "Dictionary : \n",
      " {'This': 0, 'movie': 1, 'is': 2, 'very': 3, 'sacry': 4, 'and': 5, 'long.': 6}\n"
     ]
    }
   ],
   "source": [
    "def word2bow(words : List[str], dictinory : Dict[str,int])-> List[Tuple[int,int]]:\n",
    "    word_frequencies = collections.defaultdict(int)\n",
    "    for word in words :\n",
    "        if word not in dictionary:\n",
    "            dictionary[word] = len(dictionary)\n",
    "        word_frequencies[dictionary[word]] +=1\n",
    "        \n",
    "    return list(word_frequencies.items())\n",
    "sample_text = 'This movie is very sacry and long.'\n",
    "dictionary = {}\n",
    "print('Sample Sentence : \\n', sample_text)\n",
    "print('\\n Bag of words representation : \\n', word2bow(sample_text.split(),dictionary))\n",
    "print('Dictionary : \\n', dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e426b6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Sentence : \n",
      " This movie is not scary and is slow\n",
      "\n",
      " Bag of words representation : \n",
      " [(0, 1), (1, 1), (2, 2), (3, 1), (4, 1), (5, 1), (6, 1)]\n",
      "Dictionary : \n",
      " {'This': 0, 'movie': 1, 'is': 2, 'not': 3, 'scary': 4, 'and': 5, 'slow': 6}\n"
     ]
    }
   ],
   "source": [
    "def word2bow(words : List[str], dictinory : Dict[str,int])-> List[Tuple[int,int]]:\n",
    "    word_frequencies = collections.defaultdict(int)\n",
    "    for word in words :\n",
    "        if word not in dictionary:\n",
    "            dictionary[word] = len(dictionary)\n",
    "        word_frequencies[dictionary[word]] +=1\n",
    "        \n",
    "    return list(word_frequencies.items())\n",
    "sample_text = 'This movie is not scary and is slow'\n",
    "dictionary = {}\n",
    "print('Sample Sentence : \\n', sample_text)\n",
    "print('\\n Bag of words representation : \\n', word2bow(sample_text.split(),dictionary))\n",
    "print('Dictionary : \\n', dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "462bf7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Sentence : \n",
      " Thismovie is spooky and good \n",
      "\n",
      " Bag of words representation : \n",
      " [(0, 1), (1, 1), (2, 1), (3, 1), (4, 1)]\n",
      "Dictionary : \n",
      " {'Thismovie': 0, 'is': 1, 'spooky': 2, 'and': 3, 'good': 4}\n"
     ]
    }
   ],
   "source": [
    "def word2bow(words : List[str], dictinory : Dict[str,int])-> List[Tuple[int,int]]:\n",
    "    word_frequencies = collections.defaultdict(int)\n",
    "    for word in words :\n",
    "        if word not in dictionary:\n",
    "            dictionary[word] = len(dictionary)\n",
    "        word_frequencies[dictionary[word]] +=1\n",
    "        \n",
    "    return list(word_frequencies.items())\n",
    "sample_text = 'Thismovie is spooky and good '\n",
    "dictionary = {}\n",
    "print('Sample Sentence : \\n', sample_text)\n",
    "print('\\n Bag of words representation : \\n', word2bow(sample_text.split(),dictionary))\n",
    "print('Dictionary : \\n', dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b4c869",
   "metadata": {},
   "source": [
    "# Task 2 :\n",
    "- For the text, \"Hey, Siri! Hey Siri!\", how will you define patterns and implement token-based matching so you can obtain the following outcomes:\n",
    "- a) Hey Siri\n",
    "- b) Hey, Siri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2357e4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d534263d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey Siri\n",
      "Hey,Siri\n"
     ]
    }
   ],
   "source": [
    "pattern = [{'LOWER': 'hey'},{'IS_PUNCT':True}, {'LOWER':'siri'}]\n",
    "matcher.add(\"HeySiri\",[pattern])\n",
    "doc = nlp(\"Hey Siri ! Hey,Siri!\")\n",
    "matches = matcher(doc)\n",
    "for match_id,start,end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]\n",
    "    span = doc[start:end]\n",
    "    print(span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6758a552",
   "metadata": {},
   "source": [
    "# Task 3 :\n",
    "Do the tokens 'apple','orange', 'pikkstn', 'German' have a vector represent in spacy?\n",
    "\n",
    "Are they part of the pipeline's vocabolary in spacy or out-of-vocabolary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d4ab5324",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3f710d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text = apple \t Vector =  True \t OOV= False\n",
      "Text = orange \t Vector =  True \t OOV= False\n",
      "Text = pikkstn \t Vector =  False \t OOV= True\n",
      "Text = German \t Vector =  True \t OOV= False\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"apple orange pikkstn German \")\n",
    "for token in doc:\n",
    "    print('Text =', token.text, '\\t Vector = ', token.has_vector,'\\t OOV=',token.is_oov)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0885087a",
   "metadata": {},
   "source": [
    "# Task 4 :\n",
    "For Sentence , the phrases 'rotten mangoes' and 'sweet oranges' should be matched using defined patterns \n",
    "\n",
    "How will you set the attributes to achieve this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "47d6b171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rotten mangoes\n",
      "sweet oranges\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import PhraseMatcher                                               # Import matcher\n",
    "nlp = spacy.load(\"en_core_web_sm\")                                                    # Load model\n",
    "matcher = PhraseMatcher(nlp.vocab,attr = \"LOWER\")\n",
    "terms = [\"ROTTEN mangoes\", \"sweet oranges\"]\n",
    "patterns = [nlp.make_doc(text) for text in terms]                                     # Only run nlp.make_doc to speed things up\n",
    "matcher.add(\"Name\", patterns)\n",
    "doc = nlp(\" Do not put rotten mangoes and sweet oranges together\")\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:                                                  # Find matches\n",
    "    span = doc[start:end]\n",
    "    print(span.text)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7c00fd",
   "metadata": {},
   "source": [
    "# Task 5 :\n",
    "Represent sentences in the vector form using word vector representation\n",
    "\n",
    "what is the total length of output vector?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bdc815a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "01c4c59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('I prefer the morning flight through Denmark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "191da32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of word vector : (300,)\n",
      "Shape of word vector : (300,)\n",
      "Shape of word vector : (300,)\n",
      "Shape of word vector : (300,)\n",
      "Shape of word vector : (300,)\n",
      "Shape of word vector : (300,)\n",
      "Shape of word vector : (300,)\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print('Shape of word vector :', token.vector.shape)\n",
    "    #print('word vector representation :', token.vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9158a986",
   "metadata": {},
   "source": [
    "# Task 6 :\n",
    "Find the similarity between each word of the input sentence Answeer  the following question :\n",
    "- a) The words 'rotten' and 'sweet' are out of vocabulary.  Identify that the statements  is  True or False\n",
    "- b) What are the similar values between 'mangoes' amd 'orange'?\n",
    "- c) What are the similar values between 'sweet' and 'oranges'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ff3e2cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "aec300a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text = Do \t\t Vector =  True \tOOV= False\n",
      "Text = not \t\t Vector =  True \tOOV= False\n",
      "Text = put \t\t Vector =  True \tOOV= False\n",
      "Text = rotten \t\t Vector =  True \tOOV= False\n",
      "Text = Mangoes \t\t Vector =  True \tOOV= False\n",
      "Text = and \t\t Vector =  True \tOOV= False\n",
      "Text = sweet \t\t Vector =  True \tOOV= False\n",
      "Text = oranges \t\t Vector =  True \tOOV= False\n",
      "Text = together \t\t Vector =  True \tOOV= False\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Do not put rotten Mangoes and sweet oranges together\")\n",
    "for token in doc:\n",
    "    print('Text =', token.text, '\\t\\t Vector = ', token.has_vector,'\\tOOV=',token.is_oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cf0521f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do Do 1.0\n",
      "Do not 0.09674252569675446\n",
      "Do put 0.06258345395326614\n",
      "Do rotten 0.143129363656044\n",
      "Do Mangoes -0.06087103858590126\n",
      "Do and -0.2204747200012207\n",
      "Do sweet 0.09751001745462418\n",
      "Do oranges -0.09808991849422455\n",
      "Do together -0.0882624089717865\n",
      "not Do 0.09674252569675446\n",
      "not not 1.0\n",
      "not put 0.1489800065755844\n",
      "not rotten 0.21022066473960876\n",
      "not Mangoes 0.029252247884869576\n",
      "not and 0.16654570400714874\n",
      "not sweet 0.12065061181783676\n",
      "not oranges 0.18648026883602142\n",
      "not together 0.2724917232990265\n",
      "put Do 0.06258345395326614\n",
      "put not 0.1489800065755844\n",
      "put put 1.0\n",
      "put rotten 0.270744651556015\n",
      "put Mangoes 0.05075328052043915\n",
      "put and 0.029019659385085106\n",
      "put sweet 0.10116474330425262\n",
      "put oranges 0.03935302048921585\n",
      "put together 0.1602761447429657\n",
      "rotten Do 0.143129363656044\n",
      "rotten not 0.21022066473960876\n",
      "rotten put 0.270744651556015\n",
      "rotten rotten 1.0\n",
      "rotten Mangoes 0.19770364463329315\n",
      "rotten and -0.01168384961783886\n",
      "rotten sweet 0.29018256068229675\n",
      "rotten oranges 0.253886342048645\n",
      "rotten together 0.10954765230417252\n",
      "Mangoes Do -0.06087103858590126\n",
      "Mangoes not 0.029252247884869576\n",
      "Mangoes put 0.05075328052043915\n",
      "Mangoes rotten 0.19770364463329315\n",
      "Mangoes Mangoes 1.0\n",
      "Mangoes and 0.05994473397731781\n",
      "Mangoes sweet 0.3916364908218384\n",
      "Mangoes oranges 0.4525384306907654\n",
      "Mangoes together 0.08491200953722\n",
      "and Do -0.2204747200012207\n",
      "and not 0.16654570400714874\n",
      "and put 0.029019659385085106\n",
      "and rotten -0.01168384961783886\n",
      "and Mangoes 0.05994473397731781\n",
      "and and 1.0\n",
      "and sweet 0.002490931423380971\n",
      "and oranges 0.373857319355011\n",
      "and together 0.5518457293510437\n",
      "sweet Do 0.09751001745462418\n",
      "sweet not 0.12065061181783676\n",
      "sweet put 0.10116474330425262\n",
      "sweet rotten 0.29018256068229675\n",
      "sweet Mangoes 0.3916364908218384\n",
      "sweet and 0.002490931423380971\n",
      "sweet sweet 1.0\n",
      "sweet oranges 0.4205557107925415\n",
      "sweet together 0.15105094015598297\n",
      "oranges Do -0.09808991849422455\n",
      "oranges not 0.18648026883602142\n",
      "oranges put 0.03935302048921585\n",
      "oranges rotten 0.253886342048645\n",
      "oranges Mangoes 0.4525384306907654\n",
      "oranges and 0.373857319355011\n",
      "oranges sweet 0.4205557107925415\n",
      "oranges oranges 1.0\n",
      "oranges together 0.33503127098083496\n",
      "together Do -0.0882624089717865\n",
      "together not 0.2724917232990265\n",
      "together put 0.1602761447429657\n",
      "together rotten 0.10954765230417252\n",
      "together Mangoes 0.08491200953722\n",
      "together and 0.5518457293510437\n",
      "together sweet 0.15105094015598297\n",
      "together oranges 0.33503127098083496\n",
      "together together 1.0\n"
     ]
    }
   ],
   "source": [
    "for token1 in doc:\n",
    "    for token2 in doc:\n",
    "        print(token1.text,token2.text,token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dfa65b",
   "metadata": {},
   "source": [
    "- b) What are the similar values between 'mangoes' amd 'orange'?\n",
    "- Answer : Mangoes oranges 0.4525384306907654\n",
    "\n",
    "\n",
    "\n",
    "- c) c) What are the similar values between 'sweet' and 'oranges'?\n",
    "- Answer : sweet oranges 0.4205557107925415"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
